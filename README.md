# Confronto Sistematico: FCNN vs CNN su MNIST

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-Deep%20Learning-red)
![Status](https://img.shields.io/badge/Status-Completed-success)

> **Progetto per il corso di Neural Network Deep Learning**  
> **Laurea Magistrale in Informatica** - UniversitÃ  degli Studi di Napoli Federico II  
> **Anno Accademico:** 2025/2026  
> **Autori:** Alfredo Volpe, Angelo Paolella

---

## ðŸ“‹ Descrizione del Progetto

Questo repository ospita un "laboratorio virtuale" progettato per confrontare scientificamente due paradigmi di Deep Learning fondamentali: **Fully Connected Neural Networks (FCNN)** e **Convolutional Neural Networks (CNN)**.

Utilizzando il dataset **MNIST** come benchmark, il progetto analizza come diverse scelte architetturali influenzino:
1.  **Accuratezza di classificazione** (Generalizzazione).
2.  **Efficienza parametrica** (Numero di parametri vs Performance).
3.  **Dinamiche di apprendimento** (VelocitÃ  di convergenza, Vanishing Gradient).

Il confronto segue il principio *Ceteris Paribus*: tutti gli iperparametri di controllo (Learning Rate, Ottimizzatore, Seed, Batch Size) sono mantenuti costanti per isolare l'impatto delle modifiche architetturali.

---

## ðŸ§  Architetture Analizzate

Il codice Ã¨ modulare e permette la generazione dinamica delle reti.

### 1. FCNN (Fully Connected Neural Network)
Implementata in `fcnn.py`.
*   **Caratteristiche:** Input "appiattito" (Flattening 2D -> 1D), connessioni dense.
*   **Variabili di Studio:**
    *   **ProfonditÃ :** Shallow (1 layer), Baseline (2 layers), Deep (3 layers).
    *   **Ampiezza:** Bottle-neck vs High Capacity.
    *   **Attivazioni:** ReLU, Sigmoide (analisi vanishing gradient), Tanh.

### 2. CNN (Convolutional Neural Network)
Implementata in `cnn.py`.
*   **Caratteristiche:** Sfruttamento della struttura spaziale, condivisione dei pesi, invarianza alla traslazione (Pooling).
*   **Variabili di Studio:**
    *   **Filtri (Depth Scaling):** Bassa, Media, Alta capacitÃ .
    *   **Kernel Size (Receptive Field):** 3x3 vs 5x5.
    *   **ProfonditÃ :** 2 vs 3 blocchi convoluzionali.

---

## ðŸ”¬ Metodologia Sperimentale

Per garantire la riproducibilitÃ  e l'equitÃ  del confronto, sono stati fissati i seguenti parametri di controllo nel file `confronto_fcnn_cnn.py`:

| Parametro | Valore | Note |
| :--- | :--- | :--- |
| **Ottimizzatore** | Adam | Gestione adattiva del LR |
| **Learning Rate** | 0.001 | Standard per convergenza stabile |
| **Batch Size** | 256 | Compromesso stabilitÃ /velocitÃ  |
| **Early Stopping** | Patience=5 | Prevenzione overfitting |
| **Random Seed** | 42 | RiproducibilitÃ  deterministica |
| **Weight Init** | Kaiming He | Ottimizzato per ReLU |

---

## ðŸ“Š Risultati Chiave

Dall'analisi dei risultati (disponibile nei grafici generati e nel report PDF), emergono le seguenti conclusioni:

1.  **SuperioritÃ  delle CNN:** Le CNN superano costantemente le FCNN, raggiungendo un'accuratezza >99% contro il ~98% delle migliori FCNN.
2.  **Efficienza:** Le CNN ottengono risultati migliori con **molti meno parametri**.
    *   *Esempio:* Una CNN ottimizzata (~500k parametri) batte una FCNN ad alta capacitÃ  (~800k parametri).
3.  **Dimensione del Kernel:** L'uso di kernel **5x5** (campo recettivo piÃ¹ ampio) ha prodotto il risultato migliore assoluto (**99.21%**).
4.  **Problema del Vanishing Gradient:** Le FCNN con attivazione **Sigmoide** convergono molto piÃ¹ lentamente rispetto a quelle con **ReLU**.

### Grafico Efficienza: Parametri vs Accuracy
*(Esempio concettuale basato sui dati del progetto)*
*   ðŸŸ¢ **CNN (Verde):** Alta accuracy, basso numero di parametri.
*   ðŸ”µ **FCNN (Blu):** Accuracy inferiore, alto numero di parametri.

---

## ðŸš€ Installazione e Utilizzo

### Prerequisiti
Assicurati di avere Python installato. Le dipendenze principali sono `torch`, `torchvision` e `matplotlib`.

1.  **Clona il repository:**
    ```bash
    git clone https://github.com/tuo-username/nome-repo.git
    cd nome-repo
    ```

2.  **Installa le dipendenze:**
    ```bash
    pip install torch torchvision matplotlib
    ```

3.  **Esegui gli esperimenti:**
    Per avviare la suite completa di training e confronto:
    ```bash
    python confronto_fcnn_cnn.py
    ```

    *Nota: Impostare `TEST_MODE = True` nel file `confronto_fcnn_cnn.py` per un debug rapido su poche epoche.*

---

## ðŸ“‚ Struttura dei File

```text
.
â”œâ”€â”€ cnn.py                  # Definizione classe modello Convolutional Neural Network
â”œâ”€â”€ fcnn.py                 # Definizione classe modello Fully Connected Network
â”œâ”€â”€ confronto_fcnn_cnn.py   # Script principale: training, validazione e plotting
â”œâ”€â”€ experiment_results.json # Log dei risultati (generato post-esecuzione)
â”œâ”€â”€ *.png                   # Grafici di confronto (generati post-esecuzione)
â””â”€â”€ README.md               # Documentazione
```

## ðŸŽ“ Riferimenti

Il progetto fa riferimento ai concetti trattati nel corso di Neural Network Deep Learning, in particolare:
*   *Inductive Bias* delle CNN (LocalitÃ , Sharing, Invarianza).
*   *Universal Approximation Theorem* per le FCNN.
*   Tecniche di regolarizzazione (Dropout, Batch Norm, Early Stopping).

---
*Â© 2026 Alfredo Volpe, Angelo Paolella - UniversitÃ  degli Studi di Napoli Federico II*
